{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading processed discussion board data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the clean dataset from the pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_pickle('data_clean.pkl')\n",
    "df.Message_words = df.Message_words.apply(lambda x: [i.lower() for i in x])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and cleaning models.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the models csv\n",
    "models = pd.read_csv('models.csv', header=None, names = ['brand', 'model'])\n",
    "#removing unwanted characters\n",
    "models['brand'] = models['brand'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "models['model'] = models['model'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "\n",
    "#dropping rows with: car, problem, seat, sedan\n",
    "searchfor = [\"car\", \"problem\", \"seat\", \"sedan\"]\n",
    "models = models[~models.brand.str.contains('|'.join(searchfor))]\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing models with brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list from the messages colum\n",
    "messages = df.Message_words.to_list()\n",
    "\n",
    "# numpy.where to do the replacement : replace models with their brands\n",
    "messages2 = []\n",
    "t = 0\n",
    "for m in messages:\n",
    "    for i,row in models.iterrows():\n",
    "        m = np.where(m == row['model'], row['brand'], m)\n",
    "        \n",
    "    t+=1\n",
    "    #print(t)\n",
    "        \n",
    "    messages2.append(m)\n",
    "        \n",
    "df['Message_words_v2'] = messages2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the newly obtained dataframe as a pickle\n",
    "import joblib \n",
    "df.to_pickle('df_brands.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brand Frequency Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataframe with messages where models have been replaced with brands \n",
    "df = pd.read_pickle(\"df_brands.pickle\")\n",
    "\n",
    "mentions = []\n",
    "brand_names = models.brand.unique()\n",
    "\n",
    "#creating a dummy column for each brand, 1 = brand has been mentioned in the message \n",
    "for i in brand_names: \n",
    "    count = 0\n",
    "    for j in df.Message_words_v2: \n",
    "        if(i in j):\n",
    "            count +=1 \n",
    "    \n",
    "    mentions.append(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A - Identifying Top 10 Brands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe with all brand mentions\n",
    "brand_freq = pd.DataFrame({'brand': brand_names, 'mentions': mentions})\n",
    "#dataframe with top 10 \n",
    "top10 = brand_freq.sort_values('mentions', ascending = False).head(10)\n",
    "\n",
    "top10v = top10.copy()\n",
    "\n",
    "#adding column: percentage of mentions, per brand \n",
    "pct_list = []\n",
    "for i in top10v.mentions: \n",
    "    pct = (i*100)/brand_freq.mentions.sum()\n",
    "    pct = \"{:.2f}\".format(pct)\n",
    "    pct_list.append(pct)\n",
    "\n",
    "top10v[\"Percentage_Mentions\"] = pct_list\n",
    "#renaming columns \n",
    "top10v.columns = ['Brand', 'Total_Mentions','% of Mentions']\n",
    "\n",
    "#index starting from 1 \n",
    "top10v = top10v.reset_index(drop=True)\n",
    "top10v.index += 1 \n",
    "\n",
    "#capitalizing brand names \n",
    "for i in range(len(top10v.Brand)): \n",
    "    top10v.Brand[i+1] = top10v.Brand[i+1].capitalize()\n",
    "\n",
    "top10v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all brands, mentions \n",
    "brand_freq.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#pie chart grouped by k-means clusters\n",
    "all_df = top10.copy()\n",
    "\n",
    "others_val = brand_freq.mentions.sum() - top10.mentions.sum()\n",
    "\n",
    "#index starting from 1 \n",
    "all_df = all_df.reset_index(drop=True)\n",
    "all_df.index += 1 \n",
    "\n",
    "#capitalizing brand names \n",
    "for i in range(len(all_df.brand)): \n",
    "    all_df.brand[i+1] = all_df.brand[i+1].capitalize()\n",
    "\n",
    "all_df.loc[11] = ['Other', others_val]\n",
    "\n",
    "\n",
    "k_labels = [0,0,0,2,2,2,2,1,0,1,3]\n",
    "#appending labels from k-means clustering \n",
    "all_df['labels'] = k_labels \n",
    "all_df = all_df.sort_values('labels')\n",
    "\n",
    "#plot parameters\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "data = all_df.mentions\n",
    "wedges, texts, percs = ax.pie(data, labels= all_df.brand,\n",
    "                              autopct=\"%1.1f%%\")\n",
    "\n",
    "groups = [[0, 1, 2,3], [ 4,5], [6, 7,8,9],[10]]\n",
    "\n",
    "radfraction = 0.05\n",
    "\n",
    "\n",
    "#computing the plot\n",
    "for group in groups:\n",
    "    ang = np.deg2rad((wedges[group[-1]].theta2 + wedges[group[0]].theta1) / 2)\n",
    "    for j in group:\n",
    "        center = radfraction * wedges[j].r * np.array([np.cos(ang), np.sin(ang)])\n",
    "        wedges[j].set_center(center)\n",
    "        texts[j].set_position(np.array(texts[j].get_position()) + center)\n",
    "        percs[j].set_position(np.array(percs[j].get_position()) + center)\n",
    "\n",
    "ax.autoscale(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot of total mentions\n",
    "import plotly.express as px\n",
    "fig = px.bar(top10v, y='Total_Mentions', x='Brand', text='Total_Mentions')\n",
    "fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables for each brand mention\n",
    "brand_names = top10.brand\n",
    "\n",
    "for i in brand_names: \n",
    "    y = []\n",
    "    for j in df.Message_words_v2: \n",
    "        if(i in j):\n",
    "            var = 1\n",
    "            y.append(var)\n",
    "        else: \n",
    "            var = 0\n",
    "            y.append(var)  \n",
    "    \n",
    "    df[i] = y\n",
    "\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating probability of brand occurences \n",
    "\n",
    "tot_messages = df.shape[0]\n",
    "brand_names = top10.brand.to_list()\n",
    "\n",
    "prob_df = pd.DataFrame(columns = brand_names)\n",
    "\n",
    "for i in brand_names: \n",
    "    prob =[]\n",
    "    for j in brand_names: \n",
    "        if i == j: \n",
    "            #calculating P(I)\n",
    "            prob_val = df[i].sum()/tot_messages\n",
    "            prob.append(prob_val)\n",
    "        else:\n",
    "            #calculating P(I&J)\n",
    "            both = 0\n",
    "            for c in range(tot_messages):\n",
    "                if df[i][c] == 1 & df[j][c] == 1:\n",
    "                    both += 1\n",
    "            prob_val = both/tot_messages \n",
    "            prob.append(prob_val)\n",
    "                             \n",
    "    prob_df[i] = prob\n",
    "\n",
    "#renaming the index \n",
    "prob_df.index = brand_names\n",
    "prob_df      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the lift calculation function\n",
    "def lift_calculator(a,b, prob_df):\n",
    "    prob_a = prob_df.loc[a,a]\n",
    "    prob_b = prob_df.loc[b,b]\n",
    "    porb_a_b = prob_df.loc[a,b]\n",
    "    lift = porb_a_b/ (prob_a* prob_b)\n",
    "    return lift\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating lift between brands \n",
    "\n",
    "lift_df = pd.DataFrame(columns = brand_names)\n",
    "\n",
    "for i in brand_names:\n",
    "    lift = []\n",
    "    for j in brand_names:\n",
    "        if i == j: \n",
    "            lift_val = None\n",
    "            lift.append(lift_val)\n",
    "        else: \n",
    "            lift_val = lift_calculator(i,j,prob_df)\n",
    "            lift.append(lift_val)\n",
    "    lift_df[i] = lift\n",
    "\n",
    "#renaming the index \n",
    "lift_df.index = brand_names\n",
    "lift_df  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the lower triangle of the array\n",
    "import numpy as np\n",
    "np.tril(np.ones(lift_df.shape)).astype(np.bool)[0:10,0:10]\n",
    "df_lt = lift_df.where(np.tril(np.ones(lift_df.shape)).astype(np.bool))\n",
    "df_lt\n",
    "\n",
    "\n",
    "#dealing with null values \n",
    "df_lt.fillna(df_lt.max().max()+1, inplace=True)\n",
    "\n",
    "\n",
    "#adding color coding\n",
    "def color_max_white(val, max_val):\n",
    "    color = 'white' if val == max_val else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "def highlight_max(data, color='white'):\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)\n",
    "\n",
    "max_val = df_lt.max().max()\n",
    "\n",
    "def make_pretty(styler):\n",
    "    styler.set_caption(\"Lift Ratios\")\n",
    "    styler.background_gradient(cmap='YlGnBu', axis=None).applymap(lambda x: color_max_white(x, max_val)).apply(highlight_max, axis=None)\n",
    "    return styler\n",
    "\n",
    "make_pretty(df_lt.style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse of lift: dissimilarity  measure \n",
    "diss_df = pd.DataFrame(columns = brand_names)\n",
    "\n",
    "for i in brand_names:\n",
    "    diss = []\n",
    "    for j in brand_names:\n",
    "        if i == j: \n",
    "            diss_val = 0\n",
    "            diss.append(diss_val)\n",
    "        else: \n",
    "            diss_val = 1/lift_calculator(i,j,prob_df)\n",
    "            diss.append(diss_val)\n",
    "    diss_df[i] = diss\n",
    "\n",
    "#renaming the index \n",
    "diss_df.index = brand_names\n",
    "diss_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "#reducing to two component for x,y plotting, fixing random state to observe same results each iteration\n",
    "embedding = MDS(n_components=2, random_state = 42)\n",
    "diss_df_transformed = embedding.fit_transform(diss_df)\n",
    "diss_df_transformed.shape\n",
    "\n",
    "mds_df = pd.DataFrame(diss_df_transformed)\n",
    "mds_df['names'] = brand_names\n",
    "mds_df.columns = ['component0', 'component1', 'brand']\n",
    "\n",
    "#capitalizing brand names \n",
    "for i in range(len(mds_df.brand)): \n",
    "    mds_df.brand[i] = mds_df.brand[i].capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "#plotting the MDS\n",
    "fig = px.scatter(mds_df , x=\"component0\", y= \"component1\", text = \"brand\")\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Brand Co-Mentions in the Forum for Finding the Ideal Car',\n",
    "    yaxis_title = None,\n",
    "    xaxis_title = None\n",
    ")\n",
    "\n",
    "fig.update_traces(textfont_size=14)\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the data for kmeans clustering on the MDS plot \n",
    "mds_df = mds_df.set_index('brand')\n",
    "mds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mds plot: brand comentions \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "import numpy as np\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "\n",
    "    # plot data\n",
    "    x = mds_df.component0\n",
    "    y = mds_df.component1\n",
    "    plt.scatter(x, y, s=100)\n",
    "    \n",
    "    n = mds_df.index\n",
    "    for i, txt in enumerate(n):\n",
    "        ax.annotate(txt, (x[i], y[i]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the elbow method to determine ideal number of clusters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "distortions = []\n",
    "K = range(1,5)\n",
    "\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(mds_df)\n",
    "    distortions.append(model.inertia_)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()\n",
    "\n",
    "#elbow occurs at 3 --> select k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans clustering model \n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(mds_df)\n",
    "#fitting prediction to the data\n",
    "mds_df['label']= model.predict(mds_df)\n",
    "mds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumarrizing results\n",
    "top10v.columns = ['brand', \"total\", \"pct\"]\n",
    "mds_df[\"pct_mentions\"] = top10v.pct.to_list()\n",
    "mds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first clustering plot\n",
    "\n",
    "# define and map colors\n",
    "colors = ['#DF2020', '#81DF20', '#2095DF']\n",
    "mds_df['c'] = mds_df.label.map({0:colors[0], 1:colors[1], 2:colors[2]})\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "import numpy as np\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "\n",
    "    # plot data\n",
    "    x = mds_df.component0\n",
    "    y = mds_df.component1\n",
    "    plt.scatter(x, y, c=mds_df.c, s=100)\n",
    "    \n",
    "    n = mds_df.index\n",
    "    for i, txt in enumerate(n):\n",
    "        ax.annotate(txt, (x[i], y[i]))  \n",
    "\n",
    "    # draw enclosure\n",
    "    for i in mds_df.label.unique(): \n",
    "        points = mds_df[mds_df.label == i][['component0', 'component1']].values\n",
    "        # get convex hull\n",
    "        hull = ConvexHull(points)\n",
    "        # get x and y coordinates\n",
    "        # repeat last point to close the polygon\n",
    "        x_hull = np.append(points[hull.vertices,0],\n",
    "                        points[hull.vertices,0][0])\n",
    "        y_hull = np.append(points[hull.vertices,1],\n",
    "                        points[hull.vertices,1][0])\n",
    "        # plot shape\n",
    "        plt.fill(x_hull, y_hull, alpha=0.3, c=colors[i])\n",
    "    \n",
    "        \n",
    "    plt.xlim(0,200)\n",
    "    plt.ylim(0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second clustering plot including mention volumetry\n",
    "\n",
    "# define and map colors\n",
    "colors = ['#DF2020', '#81DF20', '#2095DF']\n",
    "mds_df['c'] = mds_df.label.map({0:colors[0], 1:colors[1], 2:colors[2]})\n",
    "\n",
    "mds_df['pct_mentions'] = pd.to_numeric(mds_df['pct_mentions'])\n",
    "from scipy.spatial import ConvexHull\n",
    "import numpy as np\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "\n",
    "    # plot data\n",
    "    x = mds_df.component0\n",
    "    y = mds_df.component1\n",
    "    plt.scatter(x, y, c=mds_df.c, s=mds_df.pct_mentions*50)\n",
    "    \n",
    "    n = mds_df.index\n",
    "    for i, txt in enumerate(n):\n",
    "        ax.annotate(txt, (x[i], y[i])) \n",
    "\n",
    "    # draw enclosure\n",
    "    for i in mds_df.label.unique(): \n",
    "        points = mds_df[mds_df.label == i][['component0', 'component1']].values\n",
    "        # get convex hull\n",
    "        hull = ConvexHull(points)\n",
    "        # get x and y coordinates\n",
    "        # repeat last point to close the polygon\n",
    "        x_hull = np.append(points[hull.vertices,0],\n",
    "                        points[hull.vertices,0][0])\n",
    "        y_hull = np.append(points[hull.vertices,1],\n",
    "                        points[hull.vertices,1][0])\n",
    "        # plot shape\n",
    "        plt.fill(x_hull, y_hull, alpha=0.3, c=colors[i])\n",
    "    \n",
    "        \n",
    "    plt.xlim(0,200)\n",
    "    plt.ylim(0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph \n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "mds_df['label'] = mds_df['label'].astype(str)\n",
    "fig = px.scatter(mds_df , x=\"component0\", y= \"component1\", text = mds_df.index, color = \"label\")\n",
    "fig.update_traces(textposition='top center')\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title_text='Brand Co-Mentions in the Forum for Finding the Ideal Car',\n",
    "    yaxis_title = None,\n",
    "    xaxis_title = None\n",
    ")\n",
    "\n",
    "fig.update_traces(textfont_size=14)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d3b3dcc6eca16da334aea97cc01f60b703ca846c3f8cf6688de364faaf3a707"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
