{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000) # to read records completely\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data scraped and pre-processed in part A\n",
    "df = pd.read_pickle('data_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.read_csv('models.csv', header=None, names = ['brand', 'model'])\n",
    "models['brand'] = models['brand'].str.replace(r'[^\\w\\s]+', '', regex=True) # clean some punctuation errors (nissan.)\n",
    "models = models[~models.brand.isin(['car', 'sedan', 'problem'])] # remove rows that are not brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Message.str.contains('said').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.lower() on all words\n",
    "df.Message_words = df.Message_words.apply(lambda x: [i.lower() for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace models with brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = df.Message_words.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.where to do the replacement. Replaces only first appearance of brand.\n",
    "# ~ 5-10 minutes of execute\n",
    "messages2 = []\n",
    "t = 0\n",
    "for m in messages:\n",
    "    for i,row in models.iterrows():\n",
    "        m = np.where(m == row['model'], row['brand'], m)\n",
    "        \n",
    "    t+=1\n",
    "    \n",
    "    #print(t)\n",
    "        \n",
    "    messages2.append(m)\n",
    "        \n",
    "df['Message_words_v2'] = messages2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the occurences of changes\n",
    "m1 = df.Message_words.to_list()\n",
    "m2 = df.Message_words_v2.to_list()\n",
    "\n",
    "c = 0\n",
    "W = 0\n",
    "for i in range(len(m2)):\n",
    "    for j in range(len(m2[i])):\n",
    "        if m1[i][j] != m2[i][j]: #word by word comparison\n",
    "            c +=1\n",
    "        W += 1 # if we want to count all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{c} changes of models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[['Message_words', 'Message_words_v2']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have cases where the text says \"nissan\", \"nissan\" because we replaced the model. Let's clean that\n",
    "#Removing duplicates in lists while keeping order\n",
    "def remove_consecutive_duplicate (text): #removes consecutive duplicates\n",
    "    return np.array([i for i, j in itertools.groupby(text)])\n",
    "\n",
    "df[\"Message_words_v3\"] = df[\"Message_words_v2\"].apply(remove_consecutive_duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link attributes to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets count brand mentions in each record\n",
    "#Get a unique list of brands\n",
    "brands_list = models.brand.drop_duplicates().to_list()\n",
    "\n",
    "brands_list.extend(['lexus', 'ferrari', 'merzedesbenz', 'tesla','gm', 'peugeot', 'jeep', 'bentley', 'fiat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = df.Message_words_v3.to_list()\n",
    "\n",
    "#Get a nested list of brands mentioned in reviews\n",
    "brands_in_message = []\n",
    "for m in messages:\n",
    "    \n",
    "    brands_mentioned = []\n",
    "    for brand in brands_list:\n",
    "        if len(np.where(m == brand)[0]) >0:\n",
    "            brands_mentioned.append(brand)\n",
    "            \n",
    "    brands_in_message.append(brands_mentioned)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Brands_in_message'] = brands_in_message\n",
    "df['Qty_brands'] = df.Brands_in_message.apply(lambda x: len(x))\n",
    "df['Qty_brands'].value_counts()\n",
    "\n",
    "# 1291 messages don't mention any brand (remove them from analysis?)\n",
    "# Most messages discuss a single brand\n",
    "# Also common to compare 2 brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Qty_brands == 0, 'Message_words_v3'].head(10) # to review records with no brand mentions\n",
    "# most of them are for seeking advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign attributes mentioned in the reviews, like the power of a car, to a specific brand. For example, in the sentence \"I like the BMW for its power. On the other hand, the Honda is reliable\" we would want to assign the the attribute \"power\" to \"BMW\" and \"reliable\" to \"Honda\". We have created functions for two different approaches:\n",
    "1) assign all words found between 1st brand mention and next brand mention to 1st brand\n",
    "\n",
    "2) assign n words to each side of the brand mention to the brand. We found n = 4 to work best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First approach: link all words found between brand mention and next brand mention.\n",
    "# Except for first brand which also receives words since beginning of message\n",
    "\n",
    "m = df.Message_words_v3[9] #record 9 is a good exaple\n",
    "\n",
    "def get_attr_in_the_right(m, brand_list):\n",
    "\n",
    "    brand_dic = {}\n",
    "    for brand in brands_list:\n",
    "        ix = np.where(m == brand)[0]\n",
    "        if len(ix) > 0:\n",
    "            brand_dic[brand] = ix[0]\n",
    "\n",
    "\n",
    "    brand_dic = dict(sorted(brand_dic.items(), key=lambda x:x[1]))\n",
    "\n",
    "    brand_list = list(brand_dic.values()) + [len(m)]\n",
    "\n",
    "    review={}\n",
    "    for i, tup in enumerate(brand_dic):\n",
    "#         print(brand_dic[tup])\n",
    "#         print(tup)\n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            review[tup] = m[0:brand_list[1]]\n",
    "        else:\n",
    "            review[tup] = m[brand_list[i]:brand_list[i+1]]\n",
    "            \n",
    "    return review\n",
    "\n",
    "\n",
    "\n",
    "get_attr_in_the_right(m, brands_list) #was brand_list, ASK CARLOS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we run it for all records\n",
    "\n",
    "brand_reviews_1st_approach = []\n",
    "\n",
    "for m in df.Message_words_v3:\n",
    "\n",
    "    brand_reviews_1st_approach.append(get_attr_in_the_right(m, brands_list))\n",
    "\n",
    "# generates a list (1 entry per row) of dictionaries {brand_1: part of text corresponding, \n",
    "# brand_2: part of text corresponding,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "review_accum_1st = {i:[] for i in brands_list} #deprecated dictionary but still interesting\n",
    "\n",
    "for brand in brands_list:\n",
    "    for review in brand_reviews_1st_approach:\n",
    "        for single_review in review:\n",
    "            #print(review[single_review])\n",
    "            if single_review==brand:\n",
    "                review_accum_1st[brand].extend(review[single_review])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task E: Finding Aspirational Brands\n",
    "Approach: Measure \"ASPIRATION\" as a distance between **their market share rank** and their **positive-comments share rank**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Get a list of positive-sentiment words and count appearances for each brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import positive attributes\n",
    "pos_df = pd.read_csv('positive_indicator.csv') # words manually tagged as positive\n",
    "\n",
    "pos_attributes = list(pos_df[pos_df.positive_indicator == 1].word)\n",
    "brands = list(review_accum_1st.keys())\n",
    "\n",
    "pos_attribute_count = []\n",
    "\n",
    "for brand in brands: \n",
    "    count = 0\n",
    "    for i in pos_attributes: \n",
    "        for j in review_accum_1st[brand]: \n",
    "            if j == i:\n",
    "                count += 1\n",
    "    \n",
    "    pos_attribute_count.append(count)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({'brand': brands, 'count': pos_attribute_count})\n",
    "results_df['rel_freq'] = results_df['count']*100/results_df['count'].sum()\n",
    "results_df.sort_values('count', ascending= False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# we remove brands with count = 0 and add a rank columns\n",
    "results_df = results_df[results_df['count'] > 0 ]\n",
    "\n",
    "results_df['pos_comment_rank'] = results_df['rel_freq'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Get brand share info from an external datasource and rank the brands according to their market share\n",
    "\n",
    " - Source: GoodCarBadCar, 2019:  https://www.goodcarbadcar.net/2019-u-s-auto-sales-figures-by-brand/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share = pd.read_excel('brand_share.xlsx')\n",
    "df_share.Brand = df_share.Brand.str.lower()\n",
    "df_share['rel_share'] = df_share.YTD*100/df_share.YTD.sum()\n",
    "df_share['share_rank'] = df_share.rel_share.rank(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Merge both data sources and look for largest distances (deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share = df_share.merge(results_df, left_on = 'Brand', right_on = 'brand')\n",
    "df_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share['dif_in_rank'] = df_share.share_rank - df_share.pos_comment_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share['dif_in_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share.sort_values('dif_in_rank', ascending=False)[[\n",
    "    'Brand','share_rank', 'pos_comment_rank','dif_in_rank']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
